---
title: "Abstract Syntax"
desc: "PFPL Chpt.1: Abstract Syntax"
author: "Leo Qiao"
keywords: "plt, ast"
tags: plt
---

## 1. Object Language vs. Metalanguage

A statement like "1 + 1 = 2 is true" seems intuitive enough that people can just nod in agreement and move on with their lives. But if you take a pause to think about what it actually means, you will most likely have a hard time explaining this intuition (assuming that you are not a logician or a PL theorist).

If we stare at this statement for long enough, it seems to consist of two parts: *1 + 1 = 2* and *is true*. The first part describes some abstract thing/object denoted *1 + 1 = 2*, and the second part is some remark/property called *is true*. Putting them together, the phrase states that the object *1 + 1 = 2* has the *is true* property.

To go one step deeper, we need to understand the **languages** being used to describe the object and the property (e.g. what are "1 + 1", "=" and "is true"). By convention, the language for describing the object is aptly named the **object language**; as for the language of the property, since it is specifying properties about the object language, logicians call it the **metalanguage** (nothing to do with the metaverse). It turns out that the duo of object language and metalanguage is quite universal and powerful, and can be used to describe a ton of things.

This post will focus on using **abstract syntax** to represent the object language, and the next one will discuss **judgements** as the metalanguage.


## 2. Syntax

The general concept of syntax involves several distinct concepts.

The **surface/concrete syntax** is concerned with how phrases are displayed and usually represented by strings of characters from some alphabet. For example, in the concrete syntax of the C programming language, `++i`, `i=i+1` are syntactically valid expressions, but `i=i+` is not.

The **structural/abstract syntax** is concerned with the structure of the phrases and, in particular, how they are composed from other phrases. Since phrases are composed from other phrases, a phrase can be represented as a *tree*; therefore, at the abstract syntax level, a phrase is represented as an **abstract syntax tree**.

An extension that could be added to the abstract syntax tree is the *binding* structure of syntax. This is concerned with the introduction and use of identifiers: how they are declared, and how declared identifiers can be used. At this level, a phrase is represented as an **abstract binding tree**, which enrich abstract syntax trees with the concept of binding and scope.

The study of concrete syntax is not discussed here. This post will focus on the formalization of abstract syntax tree and abstract binding tree.


## 3. Abstract Syntax Tree

### 3.1 Informal Definitions

An **abstract syntax tree** (or **ast** for short) is an ordered tree whose leaves are **variables**, and whose interior nodes are **operators** whose **arguments** are its children. Ast's are calssified into a variety of **sorts** corresponding to different forms of syntax. A **variable** stands for an unspecified, or generic, piece of syntax of a specified sort. Ast's can be combined by an **operator**, which has an **arity** specifying the sort of the operator and the number and sorts of its arguments. An operator of sort $s$ and arity $s_1, ..., s_n$ combines $n \geq 0$ ast's of sort $s_1, ..., s_n$, respectively, into a compound ast of sort $s$.

*Note:* In the first sentence of the definitions, saying "leaves are variables" is a little misleading. Perhaps a more accurate one would be: "An ast is an ordered tree whose leaves are variables or operators of arity 0".

### 3.2 Examples

Let's have some examples. Consider a language of arithmetic expressions built from numbers, addition, and multiplication. The abstract syntax of such a language consists of a single sort $Exp$ generated by these operators:

1. For each $n \in \mathbb{N}$, an operator `num[n]`, of sort $Exp$, with no arguments.
2. Two operators, `plus` and `times`, of sort $Exp$, each with two arguments of sort $Exp$.

The expression $2+(3 \times x)$, which involves a variable $x$, would be represented by the ast `plus(num[2];times(num[3];x))` of sort $Exp$, under the assumption that $x$ is also of sort $Exp$.

Since `num[4]` is an ast of sort $Exp$, we may plug it in for $x$ in the above ast to obtain the new ast `plus(num[2];times(num[3];num[4]))`, which we usually write in a concrete syntax of $2+(3 \times 4)$.

### 3.3 Structural Induction

The tree structure of ast's provides a useful principle of reasoning, called **structural induction**. Suppose that we wish to prove that some property $P(a)$ holds for all ast's $a$ of a given sort. To show this, it is enough to consider all the ways in which $a$ can be generated and show that the property holds in each case under the assumption that it holds for its constituent ast's (if any).

In the case of the sort $Exp$ above, it means that it suffices to show:

1. The property holds for any variable $x$ of sort $Exp$: prove that $P(x)$.
2. The property holds for any number, `num[n]`: for every $n \in \mathbb{N}$, prove that $P($`num[n]`$)$.
3. Assuming that the property holds for `a1` and `a2`, prove that it holds for `plus(a1;a2)` and `times(a1;a2)`. 

Because these cases exhaust all possibilities for the formation of $a$, we are assured that $P(a)$ holds for any ast $a$ of sort $Exp$.

### 3.4 Formal Definitions

(Taken from Chapter 1 of PFPL.)

Let $S$ be a finite set of **sorts**. For a given set $S$ of sorts, an **arity** has the form $(s_1, ..., s_n)s$, which specifies the sort $s \in S$ of an operator taking $n \geq 0$ arguments, each of sort $s_i \in S$. Let $O = \{ O_{\alpha} \}$ be an arity-indexed family of disjoint sets of **operators** $O_{\alpha}$ of arity $\alpha$. If $o$ is an operator of arity $(s_1, ..., s_n)s$, we say that $o$ has sort $s$ and has $n$ arguments of sorts $s_1, ..., s_n$.

Fix a set $S$ of sorts and an arity-indexed family $O$ of sets of operators of each arity. Let $X = \{X_s\}_{s \in S}$ be a sort-indexed family of disjoint finite sets $X_s$ of **variables** $x$ of sort $s$. When $X$ is clear from context, we say that a variable $x$ is of sort $s$ if $x \in X_s$, and we say that $x$ is **fresh for** $X$, or just $fresh$ when $X$ is understood, if $x \not \in X_s$ for any sort $s$. If $x$ is fresh for $X$ and $s$ is a sort, then $X, x$ is the family of sets of variables obtained by adding $x$ to $X_s$. The notation is ambiguous in that the sort $s$ is not explicitly stated by determined from context.

The family $A[X]= \{ A[X]_s \}_{s \in S}$ of **abstract syntax trees$, or **ast's**, of sort $s$ is the smallest family satisfying the following conditions:

1. A variable of sort $s$ is an ast of sort $s$: if $x \in X_s$, then $x \in A[X]_s$.
2. Operators combine ast's: if $o$ is an operator of arity $(s_1, ..., s_n)s$, and if $a_1 \in A[X]_{s_1}, ..., a_n \in A[X]_{s_n}$, then $o(a_1;...;a_n) \in A[X]_s$.

It follows from this definition that the principle of **structural induction** can be used to prove that some property $P$ holds of every ast. To show $P(a)$ holds for every $a \in A[X]$, it is enough to show:

1. If $x \in X_s$, then $P_s(x)$.
2. If $o$ has arity $(s_1, ..., s_n)s$ and $P_{s_1}(a_1)$ and $...$ and $P_{s_n}(a_n)$, then $P_s(o(a_1;...;a_n))$.

Variables are given meaning by **substitution**. If $a \in A[X,x]_{s'}$, and $b \in A[X]_s$, then $[b/x]a \in A[X]_{s'}$ is the result of substituting $b$ for every occurrence of $x$ in $a$. The ast $a$ is called the **target**, and $x$ is called the **subject**, of the substitution. Substitution is defined by the following equations:

1. $[b/x]x = b$ and $[b/x]y = y$ if $x \neq y$.
3. $[b/x]o(a_1;...;a_n) = o([b/x]a_1;...;[b/x]a_n)$.


## 4. Abstract Binding Tree

### 4.1 Definition


## References
- Harper. (2016). Practical Foundations for Programming Languages (2nd ed.). Cambridge University Press.
